---
title: "Clever: Using PCA Leverage for Outlier Detection in High-Dimensional Data"
author: "Amanda Mejia, Preya Shah & Damon Pham"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{clever}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
library(knitr)
opts_chunk$set(autodep = TRUE)
```

## Overview

The Clever package implements the PCA leverage outlier detection method for high-dimensional (HD) data, as detailed in this manuscript:

Citation: Mejia, Amanda F., Mary Beth Nebel, Ani Eloyan, Brian Caffo, and Martin A. Lindquist. "PCA leverage: outlier detection for high-dimensional functional magnetic resonance imaging data." Biostatistics 18, no. 3 (2017): 521-536. [paper link](https://academic.oup.com/biostatistics/article/18/3/521/3056185)

In summary, the manuscript proposes a method to detect outlier observations in HD data by drawing on the traditional statistical ideas of PCA, leverage, and outlier detection. While the primary application is for detecting outlying time points in an fMRI scan, the method can also be applied to other forms of HD data, such as gene expression data.

## Method Outline

As input, the algorithm takes a __T__ x __V__ matrix, __Y__. In our case, __Y__ represents an fMRI run, where each row of __Y__ is a vectorized volume, and each column represents one timepoint. Next, the algorithm performs the following steps: 

1. Normalize the __Y__ matrix.

2. Perform PCA on the normalized __Y__ matrix using singular value decomposition (SVD), in order to obtain the PC score matrix, __U__ (of dimension __T__ x __T__).

3. To reduce the dimensions, retain the first __Q__ rows of the __U__ matrix corresponding to the first __Q__ < __T__ principal components.  We will refer to this submatrix as __A__ (of dimension __T__ x __Q__). _Note_: To choose the model order __Q__, we retain only components with a greater-than-average eigenvalue for the "mean" method, or components with kurtosis greater than 2 for the "kurtosis" method. The number kept will be further restricted if _robust distance_ will be used, since it requires __T__ to be appropriately large relative to __Q__ for estimation of the covariance matrix.

4. Now we can apply outlier detection on __A__. The primary method is _PCA leverage_, though we also propose an alternative called _robust distance_ (see paper for further details). The output of either of these outlier detection methods is a __T__ x __1__ vector representing the "outlyingness" of each time point.  

5. Thresholds are used to identify the outliers. We choose 3 thresholds, with increasing level of stringency. Our function outputs the outliers associated with each threshold.  

## Installation

Install the package from GitHub and load it:

```{r, warning = FALSE, message = FALSE, eval = FALSE}
library(devtools)
devtools::install_github('mandymejia/clever', '1.5')
```

## Tutorial Data

ABIDE is a publicly available resource of neuroimaging and phenotypic information from 1112 subjects consisting of 20 datasets collected at 16 sites (Di Martino and others, 2014). Our simulated dataset is based on resting-state fMRI scans from two subjects collected as part of the ABIDE dataset. The first dataset contains artifacts toward the beginning time point; the second is relatively artifact-free. Axial slices are used instead of the entire volumes to minimize the clever package's download time. 
 
## A Simple Example

Here, we will run through a simple example. First let's pull the data, as follows:

```{r, warning = FALSE, message = FALSE}
library(clever)
data(Dat1)
data(Dat2)
```

The fMRI data for both subjects consist of a single slice from a volume. A brain mask has been applied to vectorize the data, forming a $T\times V$ (time by voxels or vertices) data *matrix*.

```{r}
dim(Dat1)
dim(Dat2)
```

We next run clever on both datasets using all possible combinations of parameters.

```{r}
clever.Dat1.kurt.lev = clever(Dat1, choosePCs='kurtosis', trend_filtering=FALSE)
clever.Dat2.kurt.lev = clever(Dat2, trend_filtering=FALSE)

clever.Dat1.vari.lev = clever(Dat1, choosePCs = 'variance', trend_filtering=FALSE)
clever.Dat1.kurt.rds = clever(Dat1, choosePCs='kurtosis', method = 'robdist_subset', 
                              trend_filtering=FALSE)
```

```{r}
clever.Dat1.vari.rds = clever(Dat1, choosePCs = 'variance', method = 'robdist_subset', 
                              trend_filtering=FALSE)
clever.Dat1.kurt.rbd = clever(Dat1, choosePCs='kurtosis', method = 'robdist', 
                              trend_filtering=FALSE)
clever.Dat1.vari.rbd = clever(Dat1, choosePCs = 'variance', method = 'robdist', 
                              trend_filtering=FALSE)

clever.Dat2.vari.lev = clever(Dat2, choosePCs = 'variance', trend_filtering=FALSE)
clever.Dat2.kurt.rds = clever(Dat2, choosePCs='kurtosis', method = 'robdist_subset', 
                              trend_filtering=FALSE)
clever.Dat2.vari.rds = clever(Dat2, choosePCs = 'variance', method = 'robdist_subset', 
                              trend_filtering=FALSE)
clever.Dat2.kurt.rbd = clever(Dat2, choosePCs='kurtosis', method = 'robdist', 
                              trend_filtering=FALSE)
clever.Dat2.vari.rbd = clever(Dat2, choosePCs = 'variance', method = 'robdist', 
                              trend_filtering=FALSE)

clevers.Dat1 = list(clever.Dat1.kurt.lev, clever.Dat1.vari.lev, clever.Dat1.kurt.rds, clever.Dat1.vari.rds, clever.Dat1.kurt.rbd, clever.Dat1.vari.rbd)

clevers.Dat2 = list(clever.Dat2.kurt.lev, clever.Dat2.vari.lev, clever.Dat2.kurt.rds, clever.Dat2.vari.rds, clever.Dat2.kurt.rbd, clever.Dat2.vari.rbd)
```

Here are the outliers for the first dataset:

```{r warning=FALSE, message=FALSE}
library(ggpubr)
library(gridExtra)
ggplot2::theme_set(ggpubr::theme_pubr())
```

```{r fig.height=12, fig.width=8}
plt_cell = vector('list', length=6)
plt_row = vector('list', length=3)
for(j in 0:2){
  for(i in 1:2){
    plt_cell[[j*2 + i]] = plot(clevers.Dat1[[j*2 + i]], type='n')
  }
  r = c(plt_cell[(j*2+1):(j*2+2)], common.legend=T, legend='bottom', align='hv', ncol=2)
  plt_row[[j + 1]] = do.call(ggarrange, r)
}

grid.arrange(grobs=plt_row, ncol=1)
```

And for the second:

```{r fig.height=12, fig.width=8}
plt_cell = vector('list', length=6)
plt_row = vector('list', length=3)
for(j in 0:2){
  for(i in 1:2){
    plt_cell[[j*2 + i]] = plot(clevers.Dat2[[j*2 + i]], type='n')
  }
  r = c(plt_cell[(j*2+1):(j*2+2)], common.legend=T, legend='bottom', align='hv', ncol=2)
  plt_row[[j + 1]] = do.call(ggarrange, r)
}

grid.arrange(grobs=plt_row, ncol=1)
```

For the first dataset, clever identifies 59-61 and 150-151 consistently across all parameter settings. Other times are variously identified as well, with the mean method of choosing PCs tending to identify more outliers than the kurtosis method. For the second dataset, few or no outliers are identified. Overall, these results are consistent with our prior knowledge of both datasets. 

### Trend filtering

New to version 1.5 is an option to use the scores from PCATF instead of regular PCA (citation). Notice how the leverage trends are "filtered" to have flat lines in local neighborhoods. This result not only is easier to analyze visually, but also aligns with the idea that outliers shold occur in clusters if the artifact-causing phenomenon occurs over a period longer than the T_R.  

```{r}
clever.Dat1.PCATF.lev = clever(Dat1, trend_filtering=TRUE)
#clever.Dat1.PCATF.rbd = clever(Dat1, trend_filtering=TRUE, 
#                               method='robdist')
#clever.Dat1.PCATF.rbs = clever(Dat1, trend_filtering=TRUE, 
#                               method='robdist_subset')
clever.Dat2.PCATF.lev = clever(Dat2, trend_filtering=TRUE)
#clever.Dat2.PCATF.rbd = clever(Dat2, trend_filtering=TRUE, 
#                               method='robdist')
#clever.Dat2.PCATF.rbs = clever(Dat2, trend_filtering=TRUE, 
#                               method='robdist_subset')

grid.arrange(grobs=list(
  D1=plot(clever.Dat1.PCATF.lev)+ggtitle('Dat1'), 
  D2=plot(clever.Dat2.PCATF.lev)+ggtitle('Dat2')), ncol=2)
```

### Image reconstruction

We can reconstruct the original fMRI images with the mask used for vectorizing the data. See `Matrix_to_VolumeTimeSeries` in `clever/R/visualize.R` for a helper function to do this.

```{r warning=FALSE}
library(oro.nifti)
library(neurobase)

#'  Selects a timepoint from a volume time series, and returns it after adding
#'  the NIfTI header from the mask onto it.
#' @param VolumeTimeSeries A 4D matrix. Time is on the 4th dimension.
#' @param time The timepoint to select.
#' @param mask The corresponding mask.
#'
#' @return The 3D volume with the NIfTI header from the mask.
Volume_to_NIfTI <- function(VolumeTimeSeries, time, mask){
  vol <- VolumeTimeSeries[,,,time]
  vol <- copyNIfTIHeader(img=mask, arr=vol)
  return(vol)
}
```

```{r}
fname = system.file("extdata", "Dat1_mask.nii.gz", package = "clever")
Mask1 = readNIfTI(fname) #Pitt_0050048 (full of artifacts)
Img1 = Matrix_to_VolumeTimeSeries(Dat1, Mask1)

fname = system.file("extdata", "Dat2_mask.nii.gz", package = "clever")
Mask2 = readNIfTI(fname)
Img2 = Matrix_to_VolumeTimeSeries(Dat2, Mask2)
```

Below, we compare the timepoint of median leverage (first) to the timepoint of maximum leverage (second). We choose to use the kurtosis and leverage parameter settings.

```{r, fig.width=7, fig.height=4}
par(mfrow=c(1,2))
levs = clever.Dat1.kurt.lev$leverage
t_med = order(levs)[ceiling(length(levs)/2)]
t_max = which.max(levs)

image(Img1[,,,t_med], main=paste0('Median leverage (T = ', t_med, ')'))
image(Img1[,,,t_max], main=paste0('Maximum leverage (T = ', t_max, ')'))
```

The median time point appears normal, whereas the most outlying time point clearly has banding artifacts.

### leverage images

New to 1.5, clever can also display the "leverage images" for each outlying observation. There are two types: the composite of the selected PC directions, weighed by the scores for that observation (without scaling by variance), and the single PC direction with the highest score at that observation. Here are the leverage images at the 60th timepoint for the first dataset.

```{r}
Lev_Img1 = leverage_images(clever.Dat1.kurt.lev, outlier_level=1)
print('The timepoints meeting the first outlier level threshold:')
row.names(Lev_Img1$mean)

```


```{r}
Lev_Img1.mean = Matrix_to_VolumeTimeSeries(Lev_Img1$mean, Mask1)
Lev_Img1.top = Matrix_to_VolumeTimeSeries(Lev_Img1$top, Mask1)

image(Lev_Img1.mean[,,,1], main=paste0('Leverage image, mean direction (T = 60)'))
image(Lev_Img1.top[,,,1], main=paste0('Leverage image, top direction (T = 60)'))
```